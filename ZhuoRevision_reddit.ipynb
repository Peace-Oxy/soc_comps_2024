{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8f987a-e9c0-4afd-bba7-87d2ebbc1d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## download praw \n",
    "!pip install praw\n",
    "!pip install --upgrade https://github.com/praw-dev/praw/archive/master.zip\n",
    "import praw\n",
    "\n",
    "# Reddit API credentials (replace with your own)\n",
    "CLIENT_ID = 'dc3EBg9kKK2_OyV5xWqJXQ'\n",
    "CLIENT_SECRET = 'HlKaJW1s-jdGR5u5eXbihDg6FE9Lbg'\n",
    "USER_AGENT = 'seniorcomps'\n",
    "\n",
    "# Initialize the Reddit API client\n",
    "reddit = praw.Reddit(client_id=CLIENT_ID, \n",
    "                     client_secret=CLIENT_SECRET, \n",
    "                     user_agent=USER_AGENT)\n",
    "\n",
    "# Function to check if a submission contains any of the exclude words\n",
    "def contains_exclude_words(text, exclude_words):\n",
    "    text_lower = text.lower()\n",
    "    return any(word in text_lower for word in exclude_words)\n",
    "\n",
    "# Function to scrape submissions, filter based on excluded words, and save to file\n",
    "def scrape_and_filter_submissions(subreddit_name, exclude_words, num_posts=10):\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    posts = subreddit.new(limit=num_posts)\n",
    "    \n",
    "    with open(f\"{subreddit_name}_posts.txt\", \"w\", encoding='utf-8') as file:\n",
    "        for submission in posts:\n",
    "            if contains_exclude_words(submission.title, exclude_words):\n",
    "                print(f\"Skipping submission: {submission.title}\")\n",
    "                continue\n",
    "            \n",
    "            file.write(f\"Title: {submission.title}\\n\")\n",
    "            file.write(f\"Author: {submission.author}\\n\")\n",
    "            file.write(f\"Score: {submission.score}\\n\")\n",
    "            file.write(f\"URL: {submission.url}\\n\")\n",
    "            file.write(f\"Created: {submission.created_utc}\\n\")\n",
    "            file.write(f\"Content: {submission.selftext}\\n\")\n",
    "            file.write(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    print(f\"Saved posts from r/{subreddit_name} to {subreddit_name}_posts.txt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    subreddit_name = input(\"Enter the subreddit name (without r/): \")\n",
    "    num_posts = int(input(\"Enter the number of posts to save: \"))\n",
    "    exclude_words = {'trump', 'biden', 'election'}\n",
    "    scrape_and_filter_submissions(subreddit_name, exclude_words, num_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2ff0b2-5ba0-4b33-8737-44f3f72196ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
